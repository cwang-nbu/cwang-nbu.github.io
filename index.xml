<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>个人主页</title>
    <link>https://cwang-nbu.github.io/</link>
      <atom:link href="https://cwang-nbu.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>个人主页</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>zh-Hans</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://cwang-nbu.github.io/images/icon_hu38783b90c115dd0b6ecb2b58681266fe_30471_512x512_fill_lanczos_center_2.png</url>
      <title>个人主页</title>
      <link>https://cwang-nbu.github.io/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>https://cwang-nbu.github.io/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://cwang-nbu.github.io/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>https://cwang-nbu.github.io/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://cwang-nbu.github.io/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>基于超像/体素图的手势识别方法</title>
      <link>https://cwang-nbu.github.io/project/nsfc2017-project/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/project/nsfc2017-project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;国家自然科学基金 青年项目&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;手势交互是智能人机交互技术的研究热点之一，在多媒体交互、人车交互、行为分析等领域有着广泛应用前景。手势识别的准确性、实时性、抗干扰性等是手势交互系统的关键。&lt;/p&gt;
&lt;p&gt;本研究在充分研究深度和彩色图像联合处理和超像素图特征表示的基础上，提出了新的高性能静态手势识别算法，并结合三维深度卷积网络和时域卷积网络，提出了一种动态手势识别模型。本研究利用深度和骨架信息，快速且准确地提取手势图像块。并利用手掌面的法向量估计有效地了抑制旋转、形变等干扰。在此基础上，基于概率的局部多项式回归算法能高质量地修复深度图像，大大减少噪声对识别准确性的影响。本研究在结合了超像素分割、手势结构和EMD距离的基础上，提出了一种新的手势表示形式（超像素图）和一种新的距离度量标准（基于标准化超像素图的EMD距离）。基于此研究结果，所构建的静态手势识别算法，对训练数据依赖度低，同时识别精度高。&lt;/p&gt;
&lt;p&gt;在五个公开数据集上，与多个最先进算法进行比较，均取得了最好的识别准确率（99.7%, 99.4%, 97.9%, 96.6%, 97.4%）。同时，本研究设计了一种用三维卷积网络提取动态手势的短时空时特征的网络结构，结合时间卷积网络和时域注意力机制，提出了新的短时时间卷积网络模型用于动态手势识别。提出的模型能够很好的分析动态手势的时域信息，在VIVA和NVGesture这两个公开数据集上，针对不同类型的数据，取得了与最新算法相当或更高的识别精度(91.54%, 86.10%, 86.21%, 86.93%)。&lt;/p&gt;
&lt;p&gt;在提出的识别算法的基础上，本研究通过三维打印制造了机械手，并实现了两个实际应用1) 五指机器人灵巧手的镜像操控和2) 三维场景漫游。本研究对静态和动态手势识别从方法到系统搭建进行细致而全面的研究，对基于手势的人机交互系统所需要解决的问题进行了理论探索，有着重要的科学意义和应用前景。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>基于长短时域特征的动态手势识别方法</title>
      <link>https://cwang-nbu.github.io/project/zjnsfc2020-project/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/project/zjnsfc2020-project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;浙江省自然科学基金 探索项目&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;人机智能交互技术是时下各国政府和企业关注的重点，手势交互以其非接触操作的优势成为自然人机交互的研究热点之一。虽然近年来这一领域已取得了可观的进展，但手势的多样性和环境的复杂性仍然是研究和应用中面临的最大挑战。如何保证手势检测和手势识别的高精度、实时性和稳健性，已成为手势交互系统向应用推进的关键与瓶颈。&lt;/p&gt;
&lt;p&gt;因此，本项目将主要围绕手势检测和预处理，高精度手势分类算法这两个方面展开研究。基于深度相机，联合利用深度、颜色和红外信息对手势进行预处理，结合深度学习中目标检测模型，解决手势检测的稳健性问题；在时域引入注意力机制，利用三维卷积网络和时间卷积网络分别提取短时和长时动态手势特征，进而构建高精度的动态手势识别算法。本课题对动态手势识别方法进行了细致而全面的研究，为基于手势识别的人机交互系统在实际应用中迫切需要解决的问题提供了良好的理论支持，有着重要的科学意义和应用前景。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>基于超像素图EMD距离的手势识别及交互</title>
      <link>https://cwang-nbu.github.io/project/zjnsfc2016-project/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/project/zjnsfc2016-project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;浙江省自然科学基金 青年项目&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;智能人机交互技术是时下各国政府和企业关注的重点，手势交互以其非接触操作的优 势成为研究热点之一。虽然近年来已取得一定的进展，但手势的多样性和环境的复杂性仍 然是研究和应用中面临的最大挑战。如何保证手势识别的准确性和实时性，已成为手势交互系统发展的关键与瓶颈。&lt;/p&gt;
&lt;p&gt;本研究在充分研究深度和彩色图像联合处理和超像素图特征表示的基础上，提出了一种新的、更加高性能的手势识别方法。本研究利用深度和骨架信息，快速且准确地提取手势图像块。并利用手掌面的法向量估计有效地了抑制旋转、形变等干扰。在此基础上，基于概率的局部多项式回归算法能高质量地修复深度图像，大大减少噪声对识别准确性的影响。本研究在结合了超像素分割、手势结构和EMD距离的基础上，提出了一种新的手势表示形式（超像素图）和一种新的距离度量标准（基于标准化超像素图的EMD距离）。基于此研究结果，所构建的手势识别算法，对训练数据依赖度低，同时识别精度高。在五个公开数据集上，与多个最新算法进行比较，取得了最好的识别准确率。更进一步的是，本研究利用GPU加速等方法，实现了研究的手势识别算法的实时化，最终实现了两个实际应用的演示分别是1) 五指机器人灵巧手的镜像操控和2) 三维场景漫游。本研究对手势识别方法进行细致而全面的研究，为基于手势的人机交互系统迫切需要解决 的问题提供理论支持，有着重要的科学意义和应用前景。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2-4路360度环视技术</title>
      <link>https://cwang-nbu.github.io/project/adas-project/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/project/adas-project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;参与“北大深研院”和“深国科”校企合作项目&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;随着经济社会的发展，汽车越来越普及，人们对于汽车的安全性要求也随之提高。汽车的安全性能提高不仅有利于驾驶员、乘客，也间接地对城市的道路交通状况有帮助。2-4路360度环视技术作为驾驶员驾车的辅助技术，给驾驶员一个新的视角：高空鸟瞰。通过高空鸟瞰的视角对于车辆四周360度环绕有非常清楚的认识，进而可以帮助驾驶员更好的分析、判断路况，特别是在倒车入库、低速行车过程中，360度环视技术可以显著提高行车安全性。&lt;/p&gt;
&lt;p&gt;通过安装在车身上的2-4个鱼眼摄像头，获得前后左右2-4个方向的图片。对于这2-4个图片进行鱼眼矫正、视角转换、图像色差处理、环视合成这2-4个步骤，得到最终的环视图并显示在驾驶员的屏幕上，辅助驾驶员判断车子附近的情况。目前以opencv等开源的图像库为基础，构建、优化我们的360度环视系统。在此技术基础上，可以引入更多技术：图像显示方面，把2D显示转换为3D；速度方面：通过GPU加速计算，使得每一秒处理的图片更多，使得环视系统更有实时性，这些是我们增强360度环视系统的方向。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://cwang-nbu.github.io/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2021年研究生招生</title>
      <link>https://cwang-nbu.github.io/post/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%8B%9B%E7%94%9F_202103/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/post/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%8B%9B%E7%94%9F_202103/</guid>
      <description>&lt;p&gt;&lt;strong&gt;欢迎新同学加入团队&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今年名额2+1个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;郑瑜杰&lt;/li&gt;
&lt;li&gt;陶晨晨&lt;/li&gt;
&lt;li&gt;戴鑫淼&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Reweighted Dynamic Group Convolution</title>
      <link>https://cwang-nbu.github.io/publication/conference-paper-icassp2021/</link>
      <pubDate>Sun, 21 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/conference-paper-icassp2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>祝贺陈魏魏ICASSP 2021论文接收</title>
      <link>https://cwang-nbu.github.io/post/%E9%99%88%E9%AD%8F%E9%AD%8Ficassp_202103/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/post/%E9%99%88%E9%AD%8F%E9%AD%8Ficassp_202103/</guid>
      <description>&lt;p&gt;&lt;strong&gt;恭喜陈魏魏&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;论文 “Reweighted Dynamic Group Convolution” 被 ICASSP 2021 （CCF-B类）接收&lt;/p&gt;
&lt;p&gt;做图像的蹭一下NLP领域的顶会&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2020年研究生聚餐</title>
      <link>https://cwang-nbu.github.io/post/%E8%81%9A%E9%A4%90_202011/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/post/%E8%81%9A%E9%A4%90_202011/</guid>
      <description>&lt;p&gt;&lt;strong&gt;一年一度的聚餐&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;去年的烤肉店已经倒闭了，今年在华侨豪生吃自助，可惜毛乔梅和陈魏魏缺席。&lt;/p&gt;
&lt;p&gt;以后要好好拍一张照片。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2020年研究生奖学金</title>
      <link>https://cwang-nbu.github.io/post/%E5%A5%96%E5%AD%A6%E9%87%91_202010/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/post/%E5%A5%96%E5%AD%A6%E9%87%91_202010/</guid>
      <description>&lt;p&gt;&lt;strong&gt;恭喜毛乔梅获得国家奖学金&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其他同学也要加油!&lt;/p&gt;
&lt;p&gt;ps.
中央财政出资设立研究生国家奖学金，用于奖励普通高等学校(“国家奖学金”荣誉证书“国家奖学金”荣誉证书(2张)以下简称高等学校)中表现优异的全日制研究生。研究生国家奖学金每年奖励4.5万名在读研究生。其中，博士研究生1万名，硕士研究生为3.5万名。博士研究生国家奖学金奖励标准定为每生每年3万元；硕士研究生国家奖学金奖励标准定为每生每年2万元&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Unified Approach for Target Direction Finding based on Convolutional Neural Networks</title>
      <link>https://cwang-nbu.github.io/publication/conference-paper-mlsp2020/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/conference-paper-mlsp2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2020年研究生招生</title>
      <link>https://cwang-nbu.github.io/post/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%8B%9B%E7%94%9F_202005/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/post/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%8B%9B%E7%94%9F_202005/</guid>
      <description>&lt;p&gt;&lt;strong&gt;欢迎新同学加入团队&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;霍铮，陈松，龚益玲&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Zero-Shot Object Detection with Attributes based Category Similarity</title>
      <link>https://cwang-nbu.github.io/publication/journal-article-acs-zsd/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/journal-article-acs-zsd/</guid>
      <description>&lt;p&gt;&lt;strong&gt;提取码: UxQp&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>祝贺毛乔梅ISCAS接收并推荐TCAS-II</title>
      <link>https://cwang-nbu.github.io/post/%E6%AF%9B%E4%B9%94%E6%A2%85tcasii_202003/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/post/%E6%AF%9B%E4%B9%94%E6%A2%85tcasii_202003/</guid>
      <description>&lt;p&gt;&lt;strong&gt;恭喜毛乔梅&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;论文 “Zero-Shot Object Detection with Attributes based Category Similarity” 被 ISCAS 2020 和 IEEE Transactions on Circuits and Systems II: Express Briefs 接收。&lt;/p&gt;
&lt;p&gt;可以去西班牙旅游了！&lt;/p&gt;
&lt;p&gt;可惜疫情推迟到10月了，希望能成行。&lt;/p&gt;
&lt;p&gt;改成线上会议了，等着录视频。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Short-Term Temporal Convolutional Networks for Dynamic Hand Gesture Recognition</title>
      <link>https://cwang-nbu.github.io/publication/preprint-2019/</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/preprint-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://cwang-nbu.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt; 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three 
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Improved Guided Filtering Algorithm for Image Enhancement</title>
      <link>https://cwang-nbu.github.io/publication/conference-paper-icme2018/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/conference-paper-icme2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Superpixel-based color-depth restoration and dynamic environment modeling for Kinect-assisted image-based rendering systems</title>
      <link>https://cwang-nbu.github.io/publication/journal-article-tvc2018/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/journal-article-tvc2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A hand gesture recognition system based on canonical superpixel-graph</title>
      <link>https://cwang-nbu.github.io/publication/journal-article-csgemd/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/journal-article-csgemd/</guid>
      <description>&lt;p&gt;本论文获得&lt;strong&gt;2017-2018年度宁波市自然科学优秀论文奖 三等奖&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Superpixel-Based Hand Gesture Recognition With Kinect Depth Camera</title>
      <link>https://cwang-nbu.github.io/publication/journal-article-spemd/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/journal-article-spemd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://cwang-nbu.github.io/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://cwang-nbu.github.io/publication/preprint/</link>
      <pubDate>Sat, 07 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://cwang-nbu.github.io/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
